{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _(DRAFT) Beacon Runner 2050_\n",
    "\n",
    "###### May 2020, [@barnabemonnot](https://twitter.com/barnabemonnot)\n",
    "###### [Robust Incentives Group](https://github.com/ethereum/rig), Ethereum Foundation\n",
    "###### Built with specs v0.12\n",
    "\n",
    "---\n",
    "\n",
    "## TL;DR\n",
    "\n",
    "- We improve upon our second [_Beacon Runner 2049_](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb), an economics-focused simulation environment for eth2.\n",
    "- Network latencies and communications are fully represented, with each validator storing their current view of the chain or incoming blocks and attestations in a `Store` object, as defined in the [specs](https://github.com/ethereum/eth2.0-specs/blob/dev/specs/phase0/fork-choice.md#store).\n",
    "- Validator behaviours are fully modular and can be plugged to the simulation as long as they follow a simple API, to produce rich agent-based models.\n",
    "\n",
    "---\n",
    "\n",
    "We want to understand how validator behaviours map to rewards, penalties and chain outcomes. Ideally, validators who are rational are also honest, i.e., they run the eth2 protocol the way it \"should\" be run. But apart from how incentives are designed, there is no guarantee that this will indeed the case. And as we will also see, \"honesty\" may not always have a unique instantiation.\n",
    "\n",
    "In this notebook, we improve upon the [first](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner/beacon_runner.ipynb) and [second](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb) Beacon Runners by introducing a more full-fledged simulation environment.\n",
    "\n",
    "### _Previously, on..._\n",
    "\n",
    "In the [first notebook](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner/beacon_runner.ipynb), we introduced the possibility of \"wrapping\" the current specs in a [cadCAD](https://github.com/BlockScience/cadCAD) simulation environment. We defined simple _strategies_ for validators that allowed them to produce blocks and attest too. The implementation was \"centralised\" in the sense that all validators shared a common view of the chain at all time -- a situation akin to being on a network with _perfect information_ and _zero latency_.\n",
    "\n",
    "The natural next step was to relax this assumption, and allow different views of the chain to coexist. In the simplest case, these views have an empty intersection: this is the case when the network is perfectly _partitioned_, and each side of the partition works independently. [We explored in the second notebook](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb) how the _inactivity leak_, which decreases the stake of inactive validators, eventually allows for finalisation to resume. But what if this intersection is not empty? In other words, what if some validators see both sides of the partition? More generally, what if each validator has their own view of the chain, governed by the messages they have received from other validators on the network?\n",
    "\n",
    "These are the conditions we explore here. They are sufficient to represent a realistic p2p network, where validators receive updates from each other after some (random) delay. We'll reuse the network model introduced in the previous notebook, reintroduced in the next section with a brief introduction to the validator API.\n",
    "\n",
    "### Getting started\n",
    "\n",
    "[Once again](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb), we import the specs loaded with a custom configuration file, `fast`, where epochs are only 4 slots long (for demonstration purposes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import specs\n",
    "import importlib\n",
    "from eth2spec.config.config_util import prepare_config\n",
    "from eth2spec.utils.ssz.ssz_impl import hash_tree_root\n",
    "\n",
    "prepare_config(\".\", \"fast\")\n",
    "importlib.reload(specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import our network library, seen in [network.py](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2050/network.py), as well as a library of helper functions for our Beacon Runners, [brlib.py](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2050/brlib.py). Open them up! The code is not that scary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import network as nt\n",
    "import brlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on to the new stuff. We moved `honest_attest` and `honest_propose` to a new [validatorlib.py](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2050/validatorlib.py) file. This file also defines a very important class, the `BRValidator`, intended to be an abstract superclass to custom validator implementations. `BRValidator` comes packaged with a `Store`, a nifty little helper class defined in the [specs](https://github.com/ethereum/eth2.0-specs/blob/dev/specs/phase0/fork-choice.md#store) and a bunch more logic to record past actions and current parameters. We'll get to them in a short while. \n",
    "\n",
    "We intend `BRValidator` to be an abstract superclass, meaning that though it is not supposed to be instantiated, it is friendly to inheritance. Subclasses of `BRValidator` inherit its attributes and methods, and are themselves intended to follow a simple API. Subclasses of `BRValidator` must expose a `propose()` and an `attest()` method which return, respectively, a block or an attestation when queried (or `None` when they are shy and don't want to return anything yet). We provide an example implementation in [ASAPValidator.py](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2050/ASAPValidator.py), a very nice validator who always proposes and attests as soon as they can, and honestly too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import validatorlib as vlib\n",
    "from ASAPValidator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's talk about cadCAD once more. Our simulations are now stochastic, since the latency of the network means that some updates are random. cadCAD makes it easy to organise and run any number of instances as well as define the steps that take place in each instance. But our simulation state is pretty large: there are _n_ validators and for each validator, a certain amount of data to keep track of, including chain states and current unincluded blocks and attestations. With advice from [the cadCAD community](https://community.cadcad.org/t/mitigating-cadcad-overhead/140), and a nice \"tweak\" by [Danilo Lessa](https://twitter.com/danilolessa) to the source, the simulations are implemented following the pattern described [in this notebook](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/observers/observed-br2049.ipynb).\n",
    "\n",
    "In short, make sure that you clone and checkout the `tweaks` branch of [Danilo's fork](https://github.com/danlessa/cadCAD/tree/tweaks). Install cadCAD in the folder besides this notebook, in editable mode (option `-e` with `pip3` or `pipenv`). Alternatively, refer to the [Pipfile](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2050/Pipfile) included here. If you install cadCAD from pypi or any other package manager, you will get the default version and the simulations will be quite a bit slower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cadCAD.configuration import Configuration\n",
    "from cadCAD.configuration.utils import config_sim\n",
    "from cadCAD.engine import ExecutionMode, ExecutionContext, Executor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are we all set? It seems so!\n",
    "\n",
    "## Discovering the validator and network APIs\n",
    "\n",
    "We'll start slow, as we have done in previous notebooks, before moving to a bigger simulation. We loaded a specs configuration with 4 slots per epoch, so we'll instantiate 4 `ASAPValidator`s such that each will attest in a different slot.\n",
    "\n",
    "### Genesis\n",
    "\n",
    "First, we obtain a genesis state with 4 deposits registered. Second, we instantiate our validators from this state. A `Store` is created in each of them that records the genesis state root and a couple other things. Finally we ask our validators to skip the genesis block -- it is a special block at slot 0 that no one is supposed to suggest, the first block from a validator being expected at slot 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 updated data\n",
      "1 updated data\n",
      "2 updated data\n",
      "3 updated data\n",
      "0 updated data\n",
      "1 updated data\n",
      "2 updated data\n",
      "3 updated data\n"
     ]
    }
   ],
   "source": [
    "genesis_state = brlib.get_genesis_state(4, seed=\"riggerati\")\n",
    "validators = [ASAPValidator(genesis_state, i) for i in range(4)]\n",
    "brlib.skip_genesis_block(validators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the current store time is exactly `SECONDS_PER_SLOT` ahead of `genesis_time` (in our configuration, and the current canonical specs, 12 seconds). We fast-forwarded beyond the first block at 0 to the start of slot 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis time = 1578182400 seconds\n",
      "Store time = 1578182412 seconds\n",
      "Current slot = 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Genesis time =\", validators[0].store.genesis_time, \"seconds\")\n",
    "print(\"Store time =\", validators[0].store.time, \"seconds\")\n",
    "print(\"Current slot =\", validators[0].data.slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now reuse the network we had in [the second notebook](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb). The four validators are arranged along a chain, validator 0 peering with validator 1, which peers with validator 2, which peers with validator 3. We create information sets (who peers with who) to represent the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_a = nt.NetworkSet(validators=list([0,1]))\n",
    "set_b = nt.NetworkSet(validators=list([1,2]))\n",
    "set_c = nt.NetworkSet(validators=list([2,3]))\n",
    "\n",
    "net = nt.Network(validators = validators, sets = list([set_a, set_b, set_c]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposer duties\n",
    "\n",
    "When we instantiate new validators, as we have done with `ASAPValidator(genesis_state, validator_index)`, their constructor preloads a few things. First, each validator checks their proposer duties for all slots of the current epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, [False, False, False, False]),\n",
       " (1, [True, True, False, False]),\n",
       " (2, [False, False, False, True]),\n",
       " (3, [False, False, True, False])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposer_views = [(validator_index, validator.data.current_proposer_duties) \\\n",
    "                  for validator_index, validator in enumerate(net.validators)] \n",
    "proposer_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array above shows for each validator index (0, 1, 2, 3) whether they are expected to propose a block in either of the 4 slots. Notice that the randomness means the same validator could be called twice in an epoch. This is distinct from attestation duties, where each validator is expected to attest once, and only once, in each epoch.\n",
    "\n",
    "Since we are at slot 1, we see that validator 1 is expected to propose here. Let's ping them by calling their `propose` method, which expects a dictionary of \"known items\": blocks and attestations communicated over the network which may not have been included in the chain yet.\n",
    "\n",
    "Let's take a brief look at the `propose` method of the ASAP validator:\n",
    "\n",
    "```python\n",
    "def propose(self, known_items) -> Optional[specs.SignedBeaconBlock]:\n",
    "    # Not supposed to propose for current slot\n",
    "    if not self.data.current_proposer_duties[self.data.slot % specs.SLOTS_PER_EPOCH]:\n",
    "        return None\n",
    "\n",
    "    # Already proposed for this slot\n",
    "    if self.data.last_slot_proposed == self.data.slot:\n",
    "        return None\n",
    "\n",
    "    # honest propose\n",
    "    return vlib.honest_propose(self, known_items)\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each validator has a `data` attribute, the \"internals\" maintained and updated by the `BRValidator` class. By exposing the current slot, whether the validator is supposed to propose (in `current_proposer_duties`) and whether the validator proposed something already (`last_slot_proposed`), one can build fairly sophisticated strategies already.\n",
    "\n",
    "Validator 1 is the first to do anything here, so we'll leave the `known_items` attributes empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 attestations in the block\n"
     ]
    }
   ],
   "source": [
    "block = net.validators[1].propose({ \"attestations\": [], \"blocks\": [] })\n",
    "print(\"There are\", len(block.message.body.attestations), \"attestations in the block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the new block produced does not contain any attestation.\n",
    "\n",
    "Now validator 1 communicates its block to the information sets it belongs to. Since it belongs to $\\{ 0, 1 \\}$ and $\\{ 1, 2 \\}$, validators 0 and 2 receive the block at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check backlog {0, 1, 2}\n",
      "0 recorded stuff\n",
      "0 updated data\n",
      "1 recorded stuff\n",
      "1 updated data\n",
      "2 recorded stuff\n",
      "2 updated data\n"
     ]
    }
   ],
   "source": [
    "nt.disseminate_block(net, 1, block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the `data` attribute, our validators maintain a `store` which records current beacon chain states. We can access the blocks in those states or the states themselves from the hash of the block. Let's check if validators 0 and 3 have recorded the current block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: there is a block\n",
      "3: no block\n"
     ]
    }
   ],
   "source": [
    "block_root = hash_tree_root(block.message)\n",
    "\n",
    "try:\n",
    "    net.validators[0].store.blocks[block_root]\n",
    "    print(\"0: there is a block\")\n",
    "except KeyError: print(\"0: no block\")\n",
    "    \n",
    "try:\n",
    "    net.validators[3].store.blocks[block_root]\n",
    "    print(\"3: there is a block\")\n",
    "except KeyError: print(\"3: no block\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that validator 3 has not seen the block yet. In the next network update, triggered when `update_network` is called on the current `network` object, validator 2 communicates the block to validator 3. But let's not do that just yet, and instead fast-forward a little more to slot number 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 updated data\n",
      "1 updated data\n",
      "2 updated data\n",
      "3 updated data\n",
      "Validator 0 says this is slot number 2\n"
     ]
    }
   ],
   "source": [
    "for validator in net.validators:\n",
    "    validator.forward_by(specs.SECONDS_PER_SLOT)\n",
    "print(\"Validator 0 says this is slot number\", net.validators[0].data.slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attester duties\n",
    "\n",
    "Let's check who is expected to attest at slot 2. Our `BRValidator` superclass records the slot of the current epoch where validators are expected to attest, in a `current_attest_slot` attribute of their `data`. In general, computing attester or proposer duties is expensive, so we try to cache it when we can and recompute it only when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "committee_views = [validator.data.current_attest_slot for validator in net.validators] \n",
    "committee_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At slot 2, validator 2 is expected to attest. Let's check what items they currently know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validator 2 knows 1 block\n",
      "This block was proposed by validator 1 in slot 1\n"
     ]
    }
   ],
   "source": [
    "known_items = nt.knowledge_set(net, 2)\n",
    "print(\"Validator 2 knows\", len(known_items[\"blocks\"]), \"block\")\n",
    "print(\"This block was proposed by validator\", known_items[\"blocks\"][0].item.message.proposer_index,\n",
    "      \"in slot\", known_items[\"blocks\"][0].item.message.slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validator 2 knows about the block that validator 1 sent in slot 1! All is well here. Validator 2's attestation will set this block as the current head of the chain and the heat goes on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "attestation = net.validators[2].attest(known_items)\n",
    "print(attestation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah, what happened here? Validator 2 refused to attest.\n",
    "\n",
    "Let's back up a bit and see why. Validator 2 is expected to attest during slot 2. Honest validators however are supposed to leave a bit of time for block proposers to communicate their blocks. We are indeed in slot 2, but we are early into it, at the very start. Meanwhile, slots last for about 12 seconds and validators are only expected to attest a third of the way into the slot, i.e., 4 seconds in. This leaves 4 seconds for the block proposer of slot 2 to produce their block and communicate it (in reality, a bit more since producers can start producing before the end of the previous slot, at the risk of missing incoming attestations).\n",
    "\n",
    "We can also look at the `attest` code in `ASAPValidator` to see this:\n",
    "\n",
    "```python\n",
    "def attest(self, known_items) -> Optional[specs.Attestation]: \n",
    "    # Not the moment to attest\n",
    "    if self.data.current_attest_slot != self.data.slot:\n",
    "        return None\n",
    "\n",
    "    # Too early in the slot\n",
    "    if (self.store.time - self.store.genesis_time) % specs.SECONDS_PER_SLOT < 4:\n",
    "        return None\n",
    "\n",
    "    # Already attested for this slot\n",
    "    if self.data.last_slot_attested == self.data.slot:\n",
    "        return None\n",
    "\n",
    "    # honest attest\n",
    "    return vlib.honest_attest(self, known_items)\n",
    "```\n",
    "\n",
    "Alright. Let's assume that no one wants to propose anything for this slot. We'll forward everyone by 4 seconds and see if validator 2 is ready to attest then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for validator in net.validators:\n",
    "    validator.forward_by(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validator 2 says this is slot number 2\n",
      "Time is now 1578182428\n",
      "We are now 4 seconds into the slot\n"
     ]
    }
   ],
   "source": [
    "print(\"Validator 2 says this is slot number\", net.validators[2].data.slot)\n",
    "print(\"Time is now\", net.validators[2].store.time)\n",
    "print(\"We are now\",\n",
    "      (net.validators[2].store.time - net.validators[2].store.genesis_time) % specs.SECONDS_PER_SLOT, \"seconds into the slot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ready to attest now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attestation(Container)\n",
      "    aggregation_bits: SpecialBitlistView = Bitlist[2048](1 bits: 1)\n",
      "    data: AttestationData = AttestationData(Container)\n",
      "                                slot: Slot = 2\n",
      "                                index: CommitteeIndex = 0\n",
      "                                beacon_block_root: Root = 0xf72fc61a7bdada9513f30b3cea914a46ab077706d19e3775b1efe06537357d73\n",
      "                                source: Checkpoint = Checkpoint(Container)\n",
      "                                                         epoch: Epoch = 0\n",
      "                                                         root: Root = 0x0000000000000000000000000000000000000000000000000000000000000000\n",
      "                                target: Checkpoint = Checkpoint(Container)\n",
      "                                                         epoch: Epoch = 0\n",
      "                                                         root: Root = 0x2a803307598b88111d7981a1b6cad3ce98240447246fd53d11cfacb446086371\n",
      "    signature: BLSSignature = 0x000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "attestation = net.validators[2].attest(known_items)\n",
    "print(attestation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes! Validator 2 returned a well-formed attestation. ASAP validators are in a hurry, sure, but not so into a hurry that they would attest too early in the slot.\n",
    "\n",
    "_What are the dangers of attesting too early?_ Simply put, validators are rewarded for attesting to the correct head of the chain as of the slot they are attesting for. If a validator attests too early and votes for the block proposed in slot 1, after which the block for slot 2 is revealed and included in the canonical chain, the validator does not receive a reward for correctly voting on the head.\n",
    "\n",
    "_But shouldn't a validator attest as late as possible then?_ We are already entering the realm of game theory here. I like it. Maybe! Though attesting too late means that the reward obtained for being included early decreases, and if you are _really_ too late, like a few epochs late, then you are not included at all. So pick your poison here.\n",
    "\n",
    "We'll define (or you can try it yourself!) a different validator behaviour, attesting _as soon as a block is received in the slot, or no later than the end of the slot if no block comes in_. This is much unlike the current validator, who attests four seconds in no matter what. Let's look at this in a different notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to forward a bit more for validators to deign record the new attestation. By default, validators ignore incoming attestations for the slot they are currently in. This is because an attestation for slot 2 can _at the earliest_ be included in a block for slot 3. So let's jump to slot 3 by forwarding by 8 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 updated data\n",
      "1 updated data\n",
      "2 updated data\n",
      "3 updated data\n",
      "Validator 2 says this is slot number 3\n"
     ]
    }
   ],
   "source": [
    "for validator in net.validators:\n",
    "    validator.forward_by(8)\n",
    "\n",
    "print(\"Validator 2 says this is slot number\", net.validators[2].data.slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have validator 2 disseminate their attestation. In the next section we'll see how other validators react to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check backlog {1, 2, 3}\n",
      "1 recorded stuff\n",
      "1 updated data\n",
      "2 recorded stuff\n",
      "2 updated data\n",
      "3 recorded stuff\n"
     ]
    }
   ],
   "source": [
    "nt.disseminate_attestations(net, [(2, attestation)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final state\n",
    "\n",
    "We'll check the state of each validator in turn. The `store` records in its `latest_messages` attribute the latest message received from each other validators (message being \"attestation\" here). This is the _LMD_ of _LMD_-GHOST, Latest Message-Driven fork choice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(net.validators[0].store.latest_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validator 0 has an empty `latest_messages` attribute. Remember that validator 0 is not peering with validator 2. Since the network was not updated, the recent attestation from validator 2 did not make its way to validator 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: LatestMessage(epoch=0, root=0xf72fc61a7bdada9513f30b3cea914a46ab077706d19e3775b1efe06537357d73)}\n"
     ]
    }
   ],
   "source": [
    "print(net.validators[1].store.latest_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validator 1 has seen the attestation from validator 2, since they are peering together. This makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{2: LatestMessage(epoch=0, root=0xf72fc61a7bdada9513f30b3cea914a46ab077706d19e3775b1efe06537357d73)}\n"
     ]
    }
   ],
   "source": [
    "print(net.validators[2].store.latest_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, validator 2 also knows about its own attestation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(net.validators[3].store.latest_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, this is trickier. Validator 3 received validator 2's attestation, since they are peering together. But why isn't it showing here in the `latest_messages`?\n",
    "\n",
    "The reason is simple: validator 2's attestation vouches for _validator 1's block_ as the current head of the chain. But validator 3 doesn't yet know about this block! From the point of view of validator 3, the attestation might as well be vouching for an inexistent head. In our `net` object, the attestation is recorded as \"known\" by validator 3, but it cannot participate in validator 3's fork choice, until validator 3 knows about validator 1's block.\n",
    "\n",
    "So we have some intuition about what is going on behind the scenes. Let's now take a look at a larger-scale simulation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating a complete chain\n",
    "\n",
    "First up, we need to reload our libraries as we'll use a different specs configuration. The `medium` config we use has now 16 slots per epoch (see the [second notebook](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb) where we used the same configuration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_config(\".\", \"medium\")\n",
    "\n",
    "importlib.reload(specs)\n",
    "importlib.reload(nt)\n",
    "importlib.reload(brlib)\n",
    "importlib.reload(vlib)\n",
    "from ASAPValidator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll start with 100 validators, divided in two sets, with a small overlap between the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 updated data\n",
      "1 updated data\n",
      "2 updated data\n",
      "3 updated data\n",
      "4 updated data\n",
      "5 updated data\n",
      "6 updated data\n",
      "7 updated data\n",
      "8 updated data\n",
      "9 updated data\n",
      "10 updated data\n",
      "11 updated data\n",
      "12 updated data\n",
      "13 updated data\n",
      "14 updated data\n",
      "15 updated data\n",
      "16 updated data\n",
      "17 updated data\n",
      "18 updated data\n",
      "19 updated data\n",
      "20 updated data\n",
      "21 updated data\n",
      "22 updated data\n",
      "23 updated data\n",
      "24 updated data\n",
      "25 updated data\n",
      "26 updated data\n",
      "27 updated data\n",
      "28 updated data\n",
      "29 updated data\n",
      "30 updated data\n",
      "31 updated data\n",
      "32 updated data\n",
      "33 updated data\n",
      "34 updated data\n",
      "35 updated data\n",
      "36 updated data\n",
      "37 updated data\n",
      "38 updated data\n",
      "39 updated data\n",
      "40 updated data\n",
      "41 updated data\n",
      "42 updated data\n",
      "43 updated data\n",
      "44 updated data\n",
      "45 updated data\n",
      "46 updated data\n",
      "47 updated data\n",
      "48 updated data\n",
      "49 updated data\n",
      "50 updated data\n",
      "51 updated data\n",
      "52 updated data\n",
      "53 updated data\n",
      "54 updated data\n",
      "55 updated data\n",
      "56 updated data\n",
      "57 updated data\n",
      "58 updated data\n",
      "59 updated data\n",
      "60 updated data\n",
      "61 updated data\n",
      "62 updated data\n",
      "63 updated data\n",
      "64 updated data\n",
      "65 updated data\n",
      "66 updated data\n",
      "67 updated data\n",
      "68 updated data\n",
      "69 updated data\n",
      "70 updated data\n",
      "71 updated data\n",
      "72 updated data\n",
      "73 updated data\n",
      "74 updated data\n",
      "75 updated data\n",
      "76 updated data\n",
      "77 updated data\n",
      "78 updated data\n",
      "79 updated data\n",
      "80 updated data\n",
      "81 updated data\n",
      "82 updated data\n",
      "83 updated data\n",
      "84 updated data\n",
      "85 updated data\n",
      "86 updated data\n",
      "87 updated data\n",
      "88 updated data\n",
      "89 updated data\n",
      "90 updated data\n",
      "91 updated data\n",
      "92 updated data\n",
      "93 updated data\n",
      "94 updated data\n",
      "95 updated data\n",
      "96 updated data\n",
      "97 updated data\n",
      "98 updated data\n",
      "99 updated data\n",
      "0 updated data\n",
      "1 updated data\n",
      "2 updated data\n",
      "3 updated data\n",
      "4 updated data\n",
      "5 updated data\n",
      "6 updated data\n",
      "7 updated data\n",
      "8 updated data\n",
      "9 updated data\n",
      "10 updated data\n",
      "11 updated data\n",
      "12 updated data\n",
      "13 updated data\n",
      "14 updated data\n",
      "15 updated data\n",
      "16 updated data\n",
      "17 updated data\n",
      "18 updated data\n",
      "19 updated data\n",
      "20 updated data\n",
      "21 updated data\n",
      "22 updated data\n",
      "23 updated data\n",
      "24 updated data\n",
      "25 updated data\n",
      "26 updated data\n",
      "27 updated data\n",
      "28 updated data\n",
      "29 updated data\n",
      "30 updated data\n",
      "31 updated data\n",
      "32 updated data\n",
      "33 updated data\n",
      "34 updated data\n",
      "35 updated data\n",
      "36 updated data\n",
      "37 updated data\n",
      "38 updated data\n",
      "39 updated data\n",
      "40 updated data\n",
      "41 updated data\n",
      "42 updated data\n",
      "43 updated data\n",
      "44 updated data\n",
      "45 updated data\n",
      "46 updated data\n",
      "47 updated data\n",
      "48 updated data\n",
      "49 updated data\n",
      "50 updated data\n",
      "51 updated data\n",
      "52 updated data\n",
      "53 updated data\n",
      "54 updated data\n",
      "55 updated data\n",
      "56 updated data\n",
      "57 updated data\n",
      "58 updated data\n",
      "59 updated data\n",
      "60 updated data\n",
      "61 updated data\n",
      "62 updated data\n",
      "63 updated data\n",
      "64 updated data\n",
      "65 updated data\n",
      "66 updated data\n",
      "67 updated data\n",
      "68 updated data\n",
      "69 updated data\n",
      "70 updated data\n",
      "71 updated data\n",
      "72 updated data\n",
      "73 updated data\n",
      "74 updated data\n",
      "75 updated data\n",
      "76 updated data\n",
      "77 updated data\n",
      "78 updated data\n",
      "79 updated data\n",
      "80 updated data\n",
      "81 updated data\n",
      "82 updated data\n",
      "83 updated data\n",
      "84 updated data\n",
      "85 updated data\n",
      "86 updated data\n",
      "87 updated data\n",
      "88 updated data\n",
      "89 updated data\n",
      "90 updated data\n",
      "91 updated data\n",
      "92 updated data\n",
      "93 updated data\n",
      "94 updated data\n",
      "95 updated data\n",
      "96 updated data\n",
      "97 updated data\n",
      "98 updated data\n",
      "99 updated data\n",
      "Set A =  NetworkSet(validators=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65])\n",
      "Set B =  NetworkSet(validators=[50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])\n"
     ]
    }
   ],
   "source": [
    "num_validators = 100\n",
    "genesis_state = brlib.get_genesis_state(num_validators)\n",
    "validators = [ASAPValidator(genesis_state.copy(), validator_index) for validator_index in range(num_validators)]\n",
    "brlib.skip_genesis_block(validators)\n",
    "\n",
    "set_a = nt.NetworkSet(validators=list(range(0, int(num_validators * 2 / 3.0))))\n",
    "set_b = nt.NetworkSet(validators=list(range(int(num_validators / 2.0), num_validators)))\n",
    "\n",
    "network = nt.Network(validators = validators, sets=list([set_a, set_b]))\n",
    "\n",
    "print(\"Set A = \", set_a)\n",
    "print(\"Set B = \", set_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that validators 50 to 65 belong to both sets. If the intersection was completely empty, we'd be back to the partition case we saw in the [previous notebook](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb).\n",
    "\n",
    "As we have done previously, we set our `initial_conditions` to only contain the `network` object we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_conditions = {\n",
    "    'network': network\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the simulation proceed? We change the rules a bit here. In previous notebooks, we kept the pattern one simulation step = one slot. To model the effects of network latency or timeliness of validator moves, this is not enough anymore. A `frequency` parameter (in Hertz) controls _how many times per second_ we update the simulation.\n",
    "\n",
    "Here is what happens at each update:\n",
    "\n",
    "1. **(Policy)** All validators are queried to check if they want to attest at this time.\n",
    "2. **(State update)** If attestations were made, we disseminate them over the network.\n",
    "3. **(Policy)** All validators are queried to check if they want to propose a block at this time.\n",
    "4. **(State update)** If blocks were proposed, we disseminate them over the network.\n",
    "5. **(State update)** We call `tick` to move the clock by one step (= a second if `frequency` is 1, a tenth of a second if `frequency` is 10 etc). When `tick` moves the clock past the start of a new slot, validators update their internals, checking for instance their new attester or proposer duties if it's also a new epoch.\n",
    "\n",
    "Whenever `tick` is called, we also check whether we want the network to update or not, by flipping a biased coin. By \"updating the network\", we mean \"peers exchange messages\". In the chain example above, with 4 validators arranged as 0 <-> 1 <-> 2 <-> 3, it takes two network updates for a message from validator 3 to reach validator 0 (when validator 3 sends their message, we assume that it reaches all their peers instantly). The update frequency of the network is represented by the `update_rate` simulation parameter, also in Hertz. An `update_rate` of 1 means that messages spread one step further on the network each second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"frequency\": [1],\n",
    "    \"network_update_rate\": [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters are specified as lists, to accommodate _parameter sweeps_ when running the simulation multiple times with different values. We'll start with one pair, but we'll see later how changing the network update rate impacts the performance of our validators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we have our partial state update blocks which represent the substep in the simulation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "psubs = [\n",
    "    {\n",
    "        'policies': {\n",
    "            'action': brlib.attest_policy # step 1\n",
    "        },\n",
    "        'variables': {\n",
    "            'network': brlib.disseminate_attestations # step 2\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'policies': {\n",
    "            'action': brlib.propose_policy # step 3\n",
    "        },\n",
    "        'variables': {\n",
    "            'network': brlib.disseminate_blocks # step 4\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'policies': {\n",
    "        },\n",
    "        'variables': {\n",
    "            'network': brlib.tick # step 5\n",
    "        }\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now set the parameters for our run. We want to run it for `number_slots`, meaning that we need `steps` timesteps, as given by the formula below. Notice that we feed our `parameters` dictionary to the `M` key of `simulation_parameters`. This exposes the `frequency` and `update_rate` parameters to all state update functions in our simulation (here we only use it for `tick`, which updates the clock of all validators and potentially the network too)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "will simulate 6 epochs ( 24 slots ) at frequency 1 moves/second\n",
      "total 288 simulation steps\n"
     ]
    }
   ],
   "source": [
    "number_epochs = 6\n",
    "number_slots = number_epochs * specs.SLOTS_PER_EPOCH\n",
    "steps = number_slots * specs.SECONDS_PER_SLOT * parameters[\"frequency\"][0]\n",
    "\n",
    "simulation_parameters = {\n",
    "    'T': range(steps),\n",
    "    'N': 1,\n",
    "    'M': parameters\n",
    "}\n",
    "\n",
    "print(\"will simulate\", number_epochs, \"epochs (\", number_slots, \"slots ) at frequency\", vlib.frequency, \"moves/second\")\n",
    "print(\"total\", steps, \"simulation steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One last thing: we discussed before the use of a cadCAD fork that doesn't record a complete copy of the simulation state at each step. This is critical because when we set a very high `frequency`, during many steps nothing really happens: no one is proposing or attesting, but we still should ping validators to check if they want to do either. Recording the full state every step is quite wasteful! So instead, we'll define [_observers_](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/observers/observed-br2049.ipynb), or _metrics_, functions of the state that record a simple value at each step, such as the average balance of validators or the current slot. Let's write the current slot first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_slot = lambda s: s[\"network\"].validators[0].data.slot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was quite easy. Our state only includes the `network` object and since we assume all validators share a clock (or at least they are all synced to the same time) any validator's current slot will do.\n",
    "\n",
    "But let's think about how to get the average balance. Of course, this depends on _which_ beacon chain state we are looking at. Each validator maintains their own current state, which is made up of all the blocks and attestations they have seen until now. All validators may not agree on the current balances of everyone! In the extreme case of a partition, which we discussed in the [previous notebook](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb), the two sides of the partition had completely different accounts of the current distribution.\n",
    "\n",
    "![My Spydey sense is partitioned](partitionspydey.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, there is no one single correct answer. If we believe our network is fully connected (i.e., no partition), given that all validators eventually receive any message, we could just sample the distribution of any one validator and we'll have some guarantee that it's not too far off from the distribution of any other's (unless the latency is real, real bad). We could \"average the average\" over all validators' states, that would work too. But let's keep it simple and just get a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eth2 import gwei_to_eth\n",
    "\n",
    "def average_balance(state):\n",
    "    validator = state[\"network\"].validators[0]\n",
    "    head = specs.get_head(validator.store)\n",
    "    current_state = validator.store.block_states[head]\n",
    "    current_epoch = specs.get_current_epoch(current_state)\n",
    "    number_validators = len(current_state.balances)\n",
    "    return gwei_to_eth(sum(current_state.balances) / float(number_validators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a couple of custom functions to add our two observers, `current_slot` and `average_balance`, to the simulation proceedings. In the background, we record the current slot and the average balance in the state of the simulation, so we need to add them to the initial conditions as well as to the state update blocks defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cadCADsupSUP import *\n",
    "\n",
    "observers = {\n",
    "    \"current_slot\": current_slot,\n",
    "    \"average_balance\": average_balance\n",
    "}\n",
    "\n",
    "observed_ic = get_observed_initial_conditions(initial_conditions, observers)\n",
    "observed_psubs = get_observed_psubs(psubs, observers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "configs = []\n",
    "for sim_param in config_sim(simulation_parameters):  \n",
    "    config = Configuration(sim_param,\n",
    "                           initial_state=observed_ic, \n",
    "                           partial_state_update_blocks=observed_psubs)\n",
    "    configs.append(config)\n",
    "\n",
    "exec_mode = ExecutionMode()\n",
    "exec_context = ExecutionContext(exec_mode.single_proc)\n",
    "executor = Executor(exec_context, configs)\n",
    "raw_result, tensor = executor.execute()\n",
    "df = pd.DataFrame(raw_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes a little time (despite a lot of caching stuff around behind the scenes), but executes and returns a simulation transcript with our observers, in `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the average balance over time, taking slots as our time unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(\"current_slot\", \"average_balance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It increases! (Remember that our epochs are 8 slots long here) Validators are behaving well, the network latency is small enough that no message is delayed too much, it's all good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrival\n",
    "\n",
    "So what have we done here?\n",
    "\n",
    "- We have a group of validators who are all individually keeping track of their view of the beacon state.\n",
    "- Validators are on a network and communicate with each other, keeping track of known (but perhaps unincluded) attestations and blocks.\n",
    "- Whenever something changes, e.g., the beginning of a new slot/epoch or a new block/attestation received on-the-wire (as in, from the p2p network), validators update their internals to parameterise their strategies.\n",
    "- Each step, the simulation pings all validators and asks whether they want to propose or attest at this point in time. Depending on their internals, validators reply with a block or an attestation.\n",
    "\n",
    "Now that we have this nice playground for validators to roam around, we are getting close to a full-fledged _agent-based model_. But we need more agents! Who expects here that all validators will be ASAP always? And is ASAP the only \"good\" behaviour? Probably not!\n",
    "\n",
    "We'll use the framework developed in this notebook to explore these questions, with a series of smaller \"case studies\" looking at specific questions. Note that our simulation environment is still incomplete, in that validators should do more than just proposing and attesting.\n",
    "\n",
    "- Up until now we assumed proposers were taking on the responsibility of aggregating their known attestations to record them in their proposed blocks. In eth2, aggregators are separate entities, chosen randomly at each slot.\n",
    "- We also haven't given our validators the power to slash malicious validators. With a few tweaks here and there we can do that simply enough."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
