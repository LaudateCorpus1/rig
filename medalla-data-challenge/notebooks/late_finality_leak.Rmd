---
title: "Summer of 15614"
author:
- name: Barnab√© Monnot
  url: https://twitter.com/barnabemonnot
  affiliation: Robust Incentives Group, Ethereum Foundation
  affiliation_url: https://github.com/ethereum/rig
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
description: |
  Longing for epoch 15614 and finality
---

```{r setup, include=FALSE}
library(tidyverse)
library(data.table)
library(patchwork)
library(rmarkdown)

source(here::here("notebooks/lib.R"))

options(digits=10)
options(scipen = 999) 

# Make the plots a bit less pixellated
knitr::opts_chunk$set(dpi = 300)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

# A minimal theme I like
newtheme <- theme_grey() + theme(
  axis.text = element_text(size = 9),
  axis.title = element_text(size = 12),
  axis.line = element_line(colour = "#000000"),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  legend.title = element_text(size = 12),
  legend.text = element_text(size = 10),
  legend.box.background = element_blank(),
  legend.key = element_blank(),
  strip.text.x = element_text(size = 10),
  strip.background = element_rect(fill = "white")
)
theme_set(newtheme)

myred <- "#F05431"
myyellow <- "#FED152"
mygreen <- "#BFCE80"

slots_per_epoch <- 32
```

```{r eval=FALSE}
all_bxs <- add_bxs(all_bxs, 20160, 20400)
all_bxs %>% fwrite(here::here("rds_data/all_bxs.csv"))
```

```{r eval=FALSE}
all_ats <- add_ats(fread(here::here("rds_data/all_ats_post_leak.csv")), 20160, 20400)
all_ats %>% fwrite(here::here("rds_data/all_ats_post_leak.csv"))
```

```{r eval=FALSE}
committees <- add_committees(committees, 20160, 20400)
committees %>% fwrite(here::here("rds_data/committees_19900-20400.csv"))
```

```{r cache=TRUE}
all_ats <- fread(here::here("rds_data/all_ats_post_leak.csv"))
all_bxs <- fread(here::here("rds_data/all_bxs.csv"))
committees <- fread(here::here("rds_data/committees_19900-20400.csv"))
```

```{r cache=TRUE}
# Either get the last declared client by validator
client_per_validator <- all_bxs %>%
  .[, .SD[which.max(slot)], by=proposer_index, .SDcols = c("slot", "declared_client")]

# Or get the most used declared client by validator
# client_per_validator <- all_bxs %>%
#   .[, .(client_count = .N), by=.(proposer_index, declared_client)] %>%
#   .[, .SD[which.max(client_count)], by=proposer_index]
```

We look at statistics from recent epochs of Medalla. If you haven't, check out our first [exploratory notebook](https://ethereum.github.io/rig/medalla-data-challenge/notebooks/explore.html) on Medalla data.

<aside>
You can find [the source of this notebook](https://github.com/ethereum/rig/blob/master/medalla-data-challenge/notebooks/late_finality_leak.Rmd) over at the RIG repository. The code to [generate the datasets](https://github.com/ethereum/rig/blob/master/medalla-data-challenge/notebooks/lib.R) is also available.
</aside>

## Finding the declared client

We associate each validator index to a client among Lighthouse, Prysm, Nimbus, Teku and "undecided". To do so, for each canonical block produced, we inspect the graffiti. We associate the block to a client whenever the name of the client features in the graffiti (with a case-insensitive search). When the first four characters of the graffiti are `poap`, we check the last character: when the character is "a", "b", "c", "d" or "e", we guess the client producing the block is (respectively) Prysm, Lighthouse, Teku, Nimbus or Lodestar. Due to the low prevalence of Lodestar blocks, we have decided to remove it from the analysis.

Since our analysis is carried over the 300 or so latest epochs, we assume that a validator index is using the latest recorded client obtained from a block produced by that validator. When we compare the performance of a client at the beginning of the testnet (between slots 0 and 30,000), we recompute the likeliest client as the _earliest_ recorded client used by a validator index.

Additionally, we make available a list associating the validator indices to their recognised client [here](https://github.com/ethereum/rig/tree/master/medalla-data-challenge/rds_data/client_per_validator.csv). If you notice any discrepancy between this list and your own observations, please let me know on [Twitter](https://twitter.com/barnabemonnot) or Discord.

<aside>
Missing validator indices in the list correspond to validators who never produced a canonical block.
</aside>

```{r}
client_per_validator %>%
  .[, .(count=.N), by=declared_client] %>%
  ggplot() +
  geom_col(aes(x = declared_client, y = count), fill = myred) +
  ggtitle("Distribution of clients in the dataset") +
  xlab("Declared client") +
  ylab("Count")
```

## Attester duties fulfilled by validators with declared clients

We plot the latest epochs on the x-axis and align validators on the y-axis. Green cells show epochs where the validator attested, and red cells where they didn't. Note that the client is obtained from the graffiti (either from the POAP tag or if the client name is in the graffiti).

```{r}
plot_grid <- function(start_epoch, end_epoch, committees) {
  attestation_grid <- all_ats %>%
    .[att_slot >= start_epoch * slots_per_epoch & att_slot < (end_epoch + 1) * slots_per_epoch,
      .(att_slot, committee_index, attesting_indices)] %>%
    get_exploded_ats() %>%
    .[attested == 1,] %>%
    merge(committees) %>%
    .[,.(att_slot, epoch=att_slot %/% slots_per_epoch, validator_index, attested)] %>%
    merge(client_per_validator %>%
            .[, .(proposer_index, declared_client)],
          by.x = c("validator_index"), by.y = c("proposer_index")) %>%
    unique()
  
  l = list()

  for (client in c("prysm", "lighthouse", "nimbus", "teku")) {
    attestation_grid_per_client <- attestation_grid %>%
      .[epoch <= end_epoch & epoch >= start_epoch & declared_client == client] %>%
      mutate(validator_index = as.factor(validator_index),
             attested = as_factor(attested))
    
    p <- attestation_grid_per_client %>%
      ggplot() +
      geom_tile(aes(x = epoch, y = validator_index, fill = attested)) +
      scale_fill_manual(values = c(mygreen), guide=FALSE) +
      scale_x_continuous(expand = c(0, 0)) +
      facet_wrap(vars(declared_client)) +
      theme(axis.text.y=element_blank(),
            axis.ticks.y=element_blank(),
            panel.background=element_rect(fill=myred, colour=myred),
            axis.title.x = element_text(size = 7),
            axis.title.y = element_text(size = 7),
            axis.text.x = element_text(size = 7),
            strip.text = element_text(size = 8))
    
    l[[client]] <- p
  }
  
  l[["prysm"]] | l[["lighthouse"]] | l[["nimbus"]] | l[["teku"]]
}
```

<!-- ### Epoch 19,900 to 19,999 -->

<!-- ```{r, layout="l-screen", fig.height=2} -->
<!-- plot_grid(19900, 19999, committees) -->
<!-- ``` -->

### Epoch 20,000 to 20,099

A moment in time, between `r get_date_from_epoch(20000)` and `r get_date_from_epoch(20099)`.

```{r, layout="l-screen", fig.height=2}
plot_grid(20000, 20099, committees)
```

### Epoch 20,100 to 20,199

A moment in time, between `r get_date_from_epoch(20100)` and `r get_date_from_epoch(20199)`.

```{r, layout="l-screen", fig.height=2}
plot_grid(20100, 20199, committees)
```

### Epoch 20,200 to 20,299

A moment in time, between `r get_date_from_epoch(20200)` and `r get_date_from_epoch(20299)`.

```{r, layout="l-screen", fig.height=2}
plot_grid(20200, 20299, committees)
```

### Epoch 20,300 to 20,399

A moment in time, between `r get_date_from_epoch(20300)` and `r get_date_from_epoch(20399)`.

```{r, layout="l-screen", fig.height=2}
plot_grid(20300, 20399, committees)
```

### Potential staking activity

```{r}
start_epoch <- 20300
end_epoch <- 20400
```

If we wanted to, could we finalise? We look at the attesting record of validators between epochs `r start_epoch` and `r end_epoch`. We define a validator as _potentially active_ if the validator attested at least once during this period **and** their exit epoch is beyond epoch `r end_epoch`. _Active_ validators are validators who are still expected to attest -- regardless of whether they were recognised as potentially active or not. They are detected as validators whose exit epoch is beyond `r end_epoch`.

```{r cache=TRUE}
# Who has attested in the last x epochs?
potential_stake <- all_ats %>%
  .[att_slot >= start_epoch * slots_per_epoch & att_slot < (end_epoch + 1) * slots_per_epoch] %>%
  get_exploded_ats() %>%
  .[attested == 1,] %>%
  merge(committees) %>%
  .[, .(validator_index)] %>%
  unique() %>%
  .[, .(validator_index, attested=1)] %>%
  merge(get_validators(end_epoch+1), all.y = TRUE) %>%
  setnafill("const", 0, cols = c("attested"))
```

We first measure the _potential weight_, the sum of effective balances of all potentially active validators.

```{r}
w_potential_stake <- potential_stake %>%
  .[attested == 1 & exit_epoch > end_epoch] %>%
  .[, .(active_stake=sum(effective_balance))] %>%
  pull(active_stake) %>% pluck(1)

tibble(`Potential weight` = w_potential_stake) %>%
  paged_table()
```

We then look at the _active weight_, the sum of effective balances of all active validators.

```{r}
w_active_stake <- potential_stake %>%
  .[slashed == 0 & exit_epoch > end_epoch] %>%
  .[, .(active_stake=sum(effective_balance))] %>%
  pull(active_stake) %>% pluck(1)

tibble(`Active weight` = w_active_stake) %>%
  paged_table()
```

Getting the ratio between the two, we can get an idea of the highest participation rate we can expect.

```{r}
tibble(`Potential participation` = round(w_potential_stake / w_active_stake * 100, digits = 2)) %>%
  paged_table()
```

Uh oh. We need that number to get above 66.66%.

## Subset and clashing aggregations per client

Here we focus our data collection on two periods:

- Between slot 0 and slot 30,000.
- Between slot 590,000 and slot 610,000.

We first look at the number of aggregates included per declared client at both times.

```{r cache=TRUE}
att_type_per_block <- all_bxs %>%
  .[slot <= 30000 | slot >= 590000 & slot <= 610000, .(proposer_index, slot)] %>%
  merge(fread(here::here("rds_data/subset_ats.csv")) %>%
          .[, .(n_subset=sum(n_subset), n_subset_ind=sum(n_subset_ind),
                n_weakly_clashing=sum(n_weakly_clashing), n_strongly_clashing=sum(n_strongly_clashing)), by=slot],
        all.x = TRUE) %>%
  setnafill("const", 0, cols=c("n_subset", "n_subset_ind", "n_weakly_clashing", "n_strongly_clashing")) %>%
  merge(client_per_validator %>%
          .[, .(proposer_index, declared_client)],
        by.x = c("proposer_index"), by.y = c("proposer_index"))

collection_data <- all_ats %>%
  .[slot >= 59e4 & slot < 61e4,] %>%
  .[, .(included_ats = .N), by=slot] %>%
  merge(all_bxs %>%
          .[, .(slot, proposer_index)]) %>%
  merge(
    all_bxs %>%
      .[slot < 61e4, .(slot, proposer_index, declared_client)] %>%
      .[, .SD[which.max(slot)], by=proposer_index] %>%
      .[, .(proposer_index, declared_client)],
    by.x = c("proposer_index"), by.y = c("proposer_index")
  ) %>%
  union(
    fread(here::here("rds_data/all_ats_30000-.csv")) %>%
      .[, .(included_ats = .N), by=slot] %>%
      merge(all_bxs %>%
              .[, .(slot, proposer_index)]) %>%
      merge(
        all_bxs %>%
          .[slot < 61e4, .(slot, proposer_index, declared_client)] %>%
          .[, .SD[which.min(slot)], by=proposer_index] %>%
          .[, .(proposer_index, declared_client)],
        by.x = c("proposer_index"), by.y = c("proposer_index")
      )
  ) %>%
  mutate(collection=if_else(slot > 50000, "590k - 610k", "0 - 30k")) %>%
  merge(att_type_per_block %>%
          .[, .(slot, n_subset)],
        by.x = c("slot"), by.y = c("slot")) %>%
  .[declared_client != "lodestar"]
```

```{r}
collection_data %>%
  ggplot(aes(x = declared_client, y = included_ats, fill = collection)) +
  stat_summary(geom = "bar", fun = mean, position = "dodge") +
  stat_summary(geom = "errorbar", fun.data = mean_se, position = position_dodge(.9), width = 0.2) +
  scale_fill_manual(values = c(myred, myyellow), name = "Collection slots") +
  ggtitle("Average number of aggregates included per block") +
  xlab("Declared client") +
  ylab("Average number of aggregates")
```

This appears to tally up with Michael Sproul's claim over at the Eth R&D Discord:

> As far as I can tell [Lighthouse] seems to be good at not including junk on chain, and I regularly see my validators proposing blocks that aren't full, see e.g. [https://beaconcha.in/blocks?q=I%20stay%20noided](https://beaconcha.in/blocks?q=I%20stay%20noided) I'd love someone to confirm my hunch though

[Subset aggregates](https://ethereum.github.io/rig/medalla-data-challenge/notebooks/explore.html) are aggregates included in a block which are fully covered by another aggregate included in the same block. Namely, when aggregate 1 has attesting indices $I$ and aggregate 2 has attesting indices $J$, aggregate 1 is a subset aggregate when $I \subset J$. How often do these aggregates show up in various client blocks?

```{r}
att_type_per_block %>%
  filter(declared_client != "lodestar") %>%
  mutate(`Collection slots` = if_else(slot > 50000, "590k - 610k", "0 - 30k")) %>%
  ggplot(aes(x = declared_client, y = n_subset, fill = `Collection slots`)) +
  stat_summary(geom = "bar", fun = mean, position = "dodge") +
  stat_summary(geom = "errorbar", fun.data = mean_se, position = position_dodge(.9), width = 0.2) +
  scale_fill_manual(values = c(myred, myyellow)) +
  ggtitle("Average number of subset aggregates per block") +
  xlab("Declared client") +
  ylab("Average subset aggregates")
```

Since we've seen varying average number of included aggregates per client, we can normalise by looking at the average percentage of subset aggregates included in the blocks.

```{r}
 collection_data %>%
  .[, .(percent = sum(n_subset) / sum(included_ats) * 100), by=.(collection, declared_client)] %>%
  ggplot(aes(x = declared_client, y = percent, fill = collection)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c(myred, myyellow), name = "Collection slots") +
  ggtitle("Percentage of subset aggregates among included aggregates") +
  xlab("Declared client") +
  ylab("Percentage of subset aggregates in block")
```

Progress was made over time! To repeat: subset aggregates bring zero extra information on validator votes, and thus can (and should) be dropped entirely when recognised as such.

## Head and target correctness per client

```{r}
start_epoch <- 20000
end_epoch <- 24000
```

We now look at how correct the clients are at finding the target of the FFG vote and the head of the chain according to the LMD-GHOST fork choice rule, again between epochs `r start_epoch` and `r end_epoch` (slot `r start_epoch * slots_per_epoch` to slot `r (end_epoch + 1) * slots_per_epoch - 1`).

```{r cache=TRUE}
block_root_at_slot <- get_block_root_at_slot(all_bxs)
correctness_data <- get_correctness_data(
  all_ats %>%
    .[att_slot >= start_epoch * slots_per_epoch & att_slot < (end_epoch + 1) * slots_per_epoch],
  block_root_at_slot
) %>%
  get_exploded_ats() %>%
  .[attested==1, .(att_slot, committee_index, index_in_committee, correct_target, correct_head)] %>%
  unique() %>%
  merge(committees) %>%
  merge(client_per_validator %>%
          .[, .(proposer_index, declared_client)],
        by.x = c("validator_index"), by.y = c("proposer_index"))
```

```{r}
correctness_data %>%
  .[declared_client!="lodestar", .(percent_correct_head=mean(correct_head) * 100,
        percent_correct_target=mean(correct_target) * 100),
    by=declared_client] %>%
  pivot_longer(-declared_client) %>%
  ggplot(aes(x = declared_client, y = value, fill = name)) +
  geom_col(position = "dodge") +
  scale_fill_manual(values = c(myred, myyellow), name = "Attribute", labels = c("Correct head", "Correct target")) +
  ggtitle("Percentage of correct vote attributes per client") +
  xlab("Declared client") +
  ylab("Percentage of correct votes")
```

## Gaps between blocks

We look at the gap (in slots) between two consecutive blocks.

```{r}
all_bxs %>%
  .[order(slot), .(slot,last_block_slot=shift(slot, n=1, fill=NA, type="lag"))] %>%
  .[!is.na(last_block_slot), .(slot,time_passed=slot-last_block_slot)] %>%
  .[time_passed > 0,] %>%
  merge(
    all_ats %>%
      .[,.(n=.N),by=slot] %>%
      .[n <= 128]
  ) %>%
  mutate(time_passed = as_factor(time_passed)) %>%
  ggplot() +
  geom_boxplot(aes(x = time_passed, y = n)) +
  ggtitle("") +
  xlab("Slots between two consecutive blocks") +
  ylab("Included aggregates")
```

The longer the gap is, the more attestations we expect the next block to carry, as evidenced by the boxplots above. The thick line is the median number of attestations included, with the top and bottom ends of the box representing respectively the 25th and 75th quantiles.










