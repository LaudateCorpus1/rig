---
title: "Exploring Medalla data"
author:
- name: Barnab√© Monnot
  url: https://twitter.com/barnabemonnot
  affiliation: Robust Incentives Group, Ethereum Foundation
  affiliation_url: https://github.com/ethereum/rig
date: "`r Sys.Date()`"
output:
  distill::distill_article:
    toc: yes
    toc_depth: 3
  html_document:
    toc: yes
    toc_depth: '3'
    df_print: paged
description: |
  Initial exploration.
---

```{r setup, include=FALSE}
library(tidyverse)
library(glue)
library(RPostgres)
library(DBI)
library(ineq)
library(PKI)
library(rmarkdown)
library(zoo)
library(data.table)

source(here::here("notebooks/lib.R"))
source(here::here("notebooks/pw.R"))

con <- dbConnect(RPostgres::Postgres(), user="chain", password=pw)

options(digits=10)
options(scipen = 999) 

# Make the plots a bit less pixellated
knitr::opts_chunk$set(dpi = 400)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)

# A minimal theme I like
newtheme <- theme_grey() + theme(
  axis.text = element_text(size = 9),
  axis.title = element_text(size = 12),
  axis.line = element_line(colour = "#000000"),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  panel.background = element_blank(),
  legend.title = element_text(size = 12),
  legend.text = element_text(size = 10),
  legend.box.background = element_blank(),
  legend.key = element_blank(),
  strip.text.x = element_text(size = 10),
  strip.background = element_rect(fill = "white")
)
theme_set(newtheme)

myred <- "#F05431"
myyellow <- "#FED152"
mygreen <- "#BFCE80"
```

```{r}
until_epoch <- 12125
slot_chunk_res <- 25000
epoch_resolution <- 12125

slots_per_epoch <- 32
until_slot <- until_epoch * slots_per_epoch
slots_per_year <- 365.25 * 24 * 60 * 60 / 12
epochs_per_year <- slots_per_year / slots_per_epoch
```

```{r}
all_bxs <- fread(here::here("rds_data/all_bxs.csv")) %>%
  .[slot <= until_slot,]
```

```{r}
all_ats <- fread(here::here("rds_data/all_ats.csv")) %>%
  .[slot <= until_slot,]
```

```{r}
all_vs <- fread(here::here("rds_data/all_vs.csv"))
```

```{r}
all_dps <- fread(here::here("rds_data/all_dps.csv")) %>%
  .[deposit_slot <= until_slot,]
```

```{r}
capture_balances <- function(df) {
  df %>%
    select(epoch = f_epoch, validator_index = f_validator_index,
           balance = f_balance, effective_balance = f_effective_balance) %>%
    mutate_all(as.numeric)
}

val_balances <- dbGetQuery(
  con, str_c("SELECT * FROM t_validator_balances WHERE f_epoch = ", until_epoch)) %>%
  capture_balances() %>%
  as.data.table()

initial_balances <- dbGetQuery(
  con, "SELECT * FROM t_validator_balances WHERE f_epoch = 0"
) %>%
  capture_balances() %>%
  as.data.table()

# val_balances <- dbFetch(res, n = 1000) %>% capture_balances()
# while(!dbHasCompleted(res)) {
#   val_balances <- val_balances %>%
#     bind_rows(dbFetch(res, n = 1000) %>% capture_balances())
# }
```

In this notebook we explore data from the [Medalla testnet](https://ethereum.org/en/eth2/get-involved/medalla-data-challenge/). We are looking at the `r (max(all_bxs$slot) + 1)` first slots.

<aside>
You can find [the source of this notebook](https://github.com/ethereum/rig/blob/master/medalla-data-challenge/notebooks/explore.Rmd) over at the RIG repository. The code to [generate the datasets](https://github.com/ethereum/rig/blob/master/medalla-data-challenge/notebooks/create_datasets.R) is also available.
</aside>

## Data sources

### Lighthouse block export

We use a fork of [Lakshman Sankar](https://twitter.com/lakshmansankar)'s [Lighthouse block exporter](https://github.com/barnabemonnot/lighthouse_block_export) to export attestations and blocks from the finalised chain until slot `r until_slot`.

We present the main datasets below:

#### `all_ats`

Each row in this dataset corresponds to an aggregate attestation included in a block.

```{r, layout="l-body-outset"}
all_ats %>%
  head() %>%
  paged_table()
```

#### `exploded_ats`

We cast the dataset above into a long format, such that each row corresponds to an individual attestation included in a block. Note that when this individual attestation is included multiple times over multiple aggregates, it appears multiple times in the dataset.

```{r, layout="l-body-outset"}
fread(here::here("rds_data/exploded_ats_0.csv")) %>%
  arrange(att_slot, committee_index, index_in_committee) %>%
  head() %>%
  paged_table()
```

#### `individual_ats`

`exploded_ats` is the "disaggregated" version of the aggregate attestations. To check for validator performance, we often don't need to check for every inclusion of their individual attestations. `individual_ats` contains these unique, individual attestations, tagged with some extra data such as their earliest inclusion and whether they attested correctly for the target checkpoint and the head.

```{r, layout="l-body-outset"}
fread(here::here("rds_data/individual_ats_0.csv")) %>%
  arrange(att_slot, committee_index, index_in_committee) %>%
  head() %>%
  paged_table()
```

### Weald dump

[Jim McDonald](https://twitter.com/AttestantIO), from Attestant, kindly provided a treasure trove of data on the #medalla-data-challenge channel of the EthStaker Discord server. The two previous datasets could have legitimately been mined from Jim's data, but we like to get our hands dirty.

#### `all_cms`

Not too dirty though: obtaining the past record of committees (which validators are supposed to attend when) is much more computationally intensive, since it requires access to past states. Yet given that we have `r until_epoch` epochs in our dataset and a maximum of `r all_vs %>% nrow()` validators, a dataset compiling all committee assignments would have `r until_epoch * (all_vs %>% nrow())` rows, which is too much. When we need committee information, we'll pull it from the database and record intermediary datasets instead.

<aside>
Note that you can obtain past states from the [Lighthouse block exporter](https://github.com/barnabemonnot/lighthouse_block_export) too, but still need to compute the committees from them.
</aside>

```{r, layout="l-body-outset"}
dbGetQuery(
  con,
  str_c(
    "SELECT * FROM t_beacon_committees WHERE f_slot >= 0 AND f_slot < 1"
  )
) %>%
  capture_committee() %>%
  head() %>%
  paged_table()
```

#### `val_balances`

This dataset gives us validator state balances at the beginning of each epoch. Note that the _state balance_ (`balance`), the true ETH amount a validator deposited, is different from the effective balance (`effective_balance`), which measures the principal on which validators receive an interest.

<aside>
Rewards are not given out at the end of genesis epoch, so the balance would only change for rows where `epoch >= 2`.
</aside>

```{r, layout="l-body-outset"}
val_balances %>%
  head() %>%
  paged_table()
```

### Computed datasets

To ease the computational demands of this notebook, we record two datasets from which much of the analysis can be derived.

#### `stats_per_val`

For each validator, we compute a bunch of statistics, including:

- `included_ats`: The number of times their attestations were included
- `first_att`/`last_att`: The attesting slot of their earliest and latest attestation (used by [pintail](https://pintail.xyz/medalla-validator-taxonomy) to build validator types)
- `correct_targets`/`correct_heads`: How many times they correctly attested for the target checkpoint or the head
- `avg_delay`: Their average inclusion delay

```{r, layout="l-body-outset"}
fread(here::here("rds_data/stats_per_val.csv")) %>%
  select(validator_index, included_ats, first_att, last_att, correct_targets,
         correct_heads, avg_delay) %>%
  head() %>%
  paged_table()
```

#### `stats_per_slot`

We also record summary statistics for each slot. At `r until_slot` slots in our dataset, this remains manageable to query. We have the following fields:

- `included_ats`: How many attestations were received for the slot.
- `expected_ats`: How many attestations were expected for the slot.
- `correct_targets`/`correct_heads`: The number of correct target/head attestations for that slot.

```{r, layout="l-body-outset"}
fread(here::here("rds_data/stats_per_slot.csv")) %>%
  select(att_slot, included_ats, expected_ats, correct_targets, correct_heads) %>%
  head() %>%
  paged_table()
```


## Performance of duties

### Attester duties

We compare the number of included attestations with the number of expected attestations.

```{r}
fread(here::here("rds_data/stats_per_slot.csv")) %>%
  .[, slot_chunk:=att_slot %/% slot_chunk_res] %>%
  filter(slot_chunk != max(slot_chunk)) %>%
  group_by(slot_chunk) %>%
  summarise(percent_received = sum(included_ats) / sum(expected_ats) * 100) %>%
  ggplot() +
  geom_line(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_received), colour = myred) +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_received),
             colour = myred) +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_received,
    label = round(percent_received, digits = 1)),
    colour = myred, alpha = 0.7, nudge_y = -4) +
  ggtitle("Proportion of included attestations",
          subtitle=str_c("Group size = ", slot_chunk_res, " slots")) +
  xlab("Epoch") +
  ylab("Percent attested and included") +
  ylim(0, 100)
```

Clearly something went very wrong circa epoch 2,500. This is now known as the [roughtime incident](https://medium.com/prysmatic-labs/eth2-medalla-testnet-incident-f7fbc3cc934a), an issue affecting the major validator client, Prysm. It took time for the network to recover, in the process demonstrating how the [quadratic inactivity leak mechanism](https://github.com/ethereum/rig/blob/master/eth2economics/code/beaconrunner2049/beacon_runner_2049.ipynb) works. Client diversity FTW!

### Proposer duties

How many blocks are there in the canonical chain?

```{r}
tibble(slot = 0:until_slot) %>%
  left_join(all_bxs %>%
              select(slot) %>%
              mutate(proposed = 1),
            by = c("slot" = "slot")) %>%
  replace_na(list(proposed = 0)) %>%
  mutate(slot_chunk = slot %/% slot_chunk_res) %>%
  filter(slot_chunk != max(slot_chunk)) %>%
  group_by(slot_chunk) %>%
  summarise(percent_proposed = sum(proposed) / n() * 100) %>%
  ggplot() +
  geom_line(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_proposed), colour = myred) +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_proposed),
             colour = myred) +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_proposed,
    label = round(percent_proposed, digits = 1)),
    colour = myred, alpha = 0.7, nudge_y = -4) +
  ggtitle("Proportion of included blocks",
          subtitle=str_c("Group size = ", slot_chunk_res, " slots")) +
  xlab("Epoch") +
  ylab("Percent proposed and included") +
  ylim(0, 100)
```

Again, the same trough during the roughtime incident.

## Correctness of attestations

### Target checkpoint

Attestations vouch for some target checkpoint to justify. We can check whether they vouched for the correct one by comparing their `target_block_root` with the latest known block root as of the start of the attestation epoch (that's a mouthful). How many individual attestations correctly attest for the target?

```{r}
n_individual_ats <- fread(here::here("rds_data/stats_per_slot.csv")) %>%
  pull(included_ats) %>%
  sum()
n_correct_target_ats <- fread(here::here("rds_data/stats_per_slot.csv")) %>%
  pull(correct_targets) %>%
  sum()

tibble(
  Name = c("Individual attestations", "Correct target attestations", "Percent correct"),
  Value = c(n_individual_ats, n_correct_target_ats, round(n_correct_target_ats / n_individual_ats * 100, digits = 2)
  )
) %>%
  paged_table()
```

How does the correctness evolve over time?

```{r}
fread(here::here("rds_data/stats_per_slot.csv")) %>%
  .[, slot_chunk:=att_slot %/% slot_chunk_res] %>%
  .[, .(percent_correct_target=sum(correct_targets) / sum(included_ats) * 100), by=slot_chunk] %>%
  ggplot() +
  geom_line(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_target),
            colour = mygreen) +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_target),
             colour = mygreen) +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_target,
    label = round(percent_correct_target, digits = 1)),
    colour = mygreen, alpha = 0.7, nudge_y = -4) +
  ggtitle("Correct targets in included attestations",
          subtitle=str_c("Group size = ", slot_chunk_res, " slots")) +
  xlab("Epoch") +
  ylab("Percent correct targets") +
  ylim(0, 100)
```

### Head of the chain

Attestations must also vote for the correct head of the chain, as returned by the [GHOST fork choice rule]. To check for correctness, one looks at the latest block known as of the attestation slot. Possibly, this block was proposed for the same slot as the attestation `att_slot`. When the `beacon_block_root` attribute of the attestation and the latest block root match, the head is correct!

```{r}
n_correct_head_ats <- fread(here::here("rds_data/stats_per_slot.csv")) %>%
  pull(correct_heads) %>%
  sum()

tibble(
  Name = c("Individual attestations", "Correct head attestations", "Percent correct"),
  Value = c(n_individual_ats, n_correct_head_ats, round(n_correct_head_ats / n_individual_ats * 100, digits = 2)
  )
) %>%
  paged_table()
```

How does the correctness evolve over time?

```{r}
fread(here::here("rds_data/stats_per_slot.csv")) %>%
  .[, slot_chunk:=att_slot %/% slot_chunk_res] %>%
  .[, .(percent_correct_head=sum(correct_heads) / sum(included_ats) * 100), by=slot_chunk] %>%
  ggplot() +
  geom_line(aes(x = (slot_chunk * slot_chunk_res) %/% slots_per_epoch, y = percent_correct_head),
            colour = "purple") +
  geom_point(aes(x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_head),
             colour = "purple") +
  geom_text(aes(
    x = slot_chunk * slot_chunk_res %/% slots_per_epoch, y = percent_correct_head,
    label = round(percent_correct_head, digits = 1)),
    colour = "purple", alpha = 0.7, nudge_y = -4) +
  ggtitle("Correct heads in included attestations",
          subtitle=str_c("Group size = ", slot_chunk_res, " slots")) +
  xlab("Epoch") +
  ylab("Percent correct head") +
  ylim(0, 100)
```

<!-- ### Justification and finalisation -->

```{r}
# all_cms %>%
#   left_join(
#     correct_target_ats %>%
#       distinct() %>%
#       select(att_slot, committee_index, index_in_committee) %>%
#       mutate(voted = 1),
#     by = c("att_slot" = "att_slot", "committee_index" = "committee_index", "index_in_committee" = "index_in_committee")
#   ) %>%
#   replace_na(list(voted = 0)) %>%
#   inner_join(val_balances,
#              by = c("epoch" = "epoch", "validator_index" = "validator_index")) %>%
#   mutate(effective_balance = effective_balance / (1e9)) %>%
#   group_by(epoch) %>%
#   summarise(attested_stake = sum(voted * effective_balance),
#             percent_attested = sum(voted * balance) / sum(balance))
```

## Validator performance

Validators are rewarded for their performance, and penalised for failing to complete their tasks. We start with a crude measure of performance: the number of included attestations. It is a crude measure since (a) we do not discount the timeliness of the validator, measured by the inclusion delay and (b) we do not check that the attestation's attributes are correct (with the exception of the `source` attribute, since an incorrect source cannot possibly be included on-chain).

### Uptime-rewards curve I: Included attestations

We compare the percentage of included attestations with the (possibly negative) reward obtained by the validator.

```{r}
bxs_proposed_per_val <- all_vs %>%
  .[, .(validator_index)] %>%
  merge(
    all_bxs %>%
      .[, .(blocks_proposed=.N), by=proposer_index],
    by.x = c("validator_index"),
    by.y = c("proposer_index"),
    all.x = TRUE
  ) %>%
  setnafill(type = "const", fill = 0, cols = c("blocks_proposed"))
```

```{r}
included_ats_per_val <- fread(here::here("rds_data/stats_per_val.csv")) %>%
  .[, .(validator_index, included_ats)]
```

```{r}
# Doesn't work, we are missing deposits, e.g., from block 150495
#
# deposits_per_val <- all_dps %>%
#   merge(all_vs %>% select(validator_index, activation_epoch)) %>%
#   filter(activation_epoch == 0) %>%
#   group_by(validator_index) %>%
#   summarise(extra_balance = sum(amount)) %>%
#   union(
#     all_dps %>%
#       merge(all_vs %>% select(validator_index, activation_epoch)) %>%
#       filter(activation_epoch != 0) %>%
#       group_by(validator_index) %>%
#       summarise(extra_balance = sum(amount) - 32 * (10 ^ 9))
#   ) %>%
#   union(
#     initial_balances %>%
#       mutate(extra_balance = balance - 32 * (10 ^ 9)) %>%
#       select(validator_index, extra_balance) %>%
#       arrange(desc(extra_balance))
#   ) %>%
#   group_by(validator_index) %>%
#   summarise(extra_balance = sum(extra_balance))
# 
# rewards_per_val <- included_ats_per_val %>%
#   merge(bxs_proposed_per_val, by="validator_index") %>%
#   merge(all_vs %>% select(validator_index, time_active)) %>%
#   merge(
#     deposits_per_val,
#     by="validator_index",
#     all.x = TRUE
#   ) %>%
#   setnafill(type="const", fill=0, cols=c("extra_balance")) %>%
#   merge(
#     val_balances,
#     by = c("validator_index" = "validator_index")
#   ) %>%
#   mutate(
#     true_balance = balance - extra_balance,
#     balance_diff = (true_balance - 32 * (10 ^ 9)) / balance * 100 * epochs_per_year / time_active
#   )
```

```{r}
rewards_per_val <- included_ats_per_val %>%
  merge(bxs_proposed_per_val, by="validator_index") %>%
  merge(all_vs %>% select(validator_index, time_active)) %>%
  merge(
    val_balances,
    by = c("validator_index" = "validator_index")
  ) %>%
  mutate(
    balance = if_else(balance < 16e9, 16e9+1, balance),
    round_balance = round(balance / (32e9)) * 32e9,
    true_rewards = balance - round_balance,
    balance_diff = true_rewards / (32e9) * 100 * epochs_per_year / time_active
  )
```


```{r}
rewards_per_val %>%
  filter(abs(balance_diff - mean(rewards_per_val$balance_diff)) <
           sd(rewards_per_val$balance_diff)) %>%
  mutate(percent_attested = included_ats / (time_active + 1) * 100) %>% {
    ggplot(., aes(x = percent_attested, y = balance_diff)) +
      geom_point(alpha = 0.2, colour = myred) +
      geom_hline(yintercept = 0, colour = "steelblue", linetype = "dashed") +
      ggtitle("Uptime-rewards curve",
              subtitle=str_c("Number of validators = ", nrow(.))) +
      xlab("Percent of epochs attested") +
      ylab("Annualised reward (%)")
  }
```
<aside>
We only show return rates within one standard deviations of the mean. Very low reward rates are incurred by slashed validators.
</aside>

Who are the validators getting a negative return? We plot the same, showing how long a validator has been in service.

```{r}
uptime_rewards <- rewards_per_val %>%
  filter(abs(balance_diff - mean(rewards_per_val$balance_diff)) <
           sd(rewards_per_val$balance_diff)) %>%
  mutate(percent_attested = included_ats / (time_active + 1) * 100) %>%
  left_join(
    fread(here::here("rds_data/stats_per_val.csv")) %>%
      .[, percent_correct_heads:=correct_heads/included_ats]
  ) %>%
  replace_na(list(percent_correct_heads = 0))

uptime_rewards %>%
  ggplot() +
  geom_point(aes(x = percent_attested, y = balance_diff, colour = time_active), alpha = 0.05) +
  geom_hline(yintercept = 0, colour = "steelblue", linetype = "dashed") +
  scale_color_viridis_c() +
  ggtitle("Uptime-rewards curve",
          subtitle=str_c("Number of validators = ", nrow(uptime_rewards))) +
  # scale_color_manual(name = "Head correct", values = c(myred, mygreen)) +
  # facet_wrap(vars(blocks_proposed), ncol = 2) +
  xlab("Percent of epochs attested") +
  ylab("Annualised reward (%)")
```

Recently activated validators have a much more balanced uptime-reward curve, with the higher performers getting positive returns. Meanwhile, validators who were active since the beginning tend to have smaller returns. This can be due to validator fatigue (validating for a while, then turning off the rig), but a fair number of early validators have high attestation performance yet low return. The roughtime incident is likely to blame here. Let's focus on these early validators.

```{r}
cut_off <- 3500
uptime_rewards %>%
  mutate(`Activation epoch` = if_else(time_active > (12125 - cut_off),
                                      str_c("Early validators (activation before epoch ", cut_off, ")"),
                                      str_c("Late validators (activation after epoch ", cut_off, ")"))) %>%
  ggplot() +
  geom_point(aes(x = percent_attested, y = balance_diff,
                 group=`Activation epoch`, color=`Activation epoch`),
             alpha = 0.2) +
  geom_hline(yintercept = 0, colour = "steelblue", linetype = "dashed") +
  scale_color_manual(values = c(myred, mygreen)) +
  facet_wrap(vars(`Activation epoch`)) +
  ggtitle("Uptime-rewards curve",
          subtitle=str_c("Number of validators = ", nrow(uptime_rewards))) +
  xlab("Percent of epochs attested") +
  ylab("Annualised reward (%)") +
  guides(color=FALSE)
```

Inactivity leaks push the uptime-rewards curve downwards. At best, validators can preserve their current balance if they validate optimally, with inclusion delay at 1 always. Most likely, active validators lose a small amount of their balance due to delay or attestation errors, while inactive validators leak much more.

### Uptime-rewards curve II: Inclusion delay

We turn our attention to the inclusion delay. Validators are rewarded for attesting timely, with higher rewards the earlier they are included in a block. We explode aggregates contained in the blocks to trace the earliest included attestation of each validator in an epoch.

```{r}
n_individual_ats <- readRDS(here::here("rds_data/n_individual_ats.rds"))
readRDS(here::here("rds_data/inclusion_delay_hist.rds")) %>%
  ggplot() +
  geom_col(aes(x = inclusion_delay, y = count), fill="steelblue") +
  scale_y_log10() +
  ggtitle("Histogram of inclusion delay per individual attestation",
          subtitle = str_c("Individual attestations = ", n_individual_ats)) +
  xlab("Inclusion delay") +
  ylab("Count (log10)")
```

Note that the y axis is given on a logarithmic scale. A high number of attestations have a low inclusion delay, which is good! Since attestations cannot be included more than 32 slots from their attesting slot, the distribution above is naturally capped at 32.

How is the inclusion delay correlated with the rewards? We look at validators with at least 70% of included attestations and activated after the roughtime incident to find out. 

```{r}
fread(here::here("rds_data/stats_per_val.csv")) %>%
  merge(rewards_per_val %>% as.data.table(),
        by=c("validator_index", "included_ats")) %>%
  .[time_active < 7000,] %>%
  .[included_ats > 0.7 * max(included_ats) & balance_diff < 100,] %>% {
    ggplot(., aes(x = avg_delay, y = balance_diff)) +
      geom_point(alpha = 0.2, colour = myred) +
      geom_hline(yintercept = 0, colour = "steelblue", linetype = "dashed") +
      ggtitle("Annualised reward per average inclusion delay for high performing validators",
              subtitle = str_c("Validators = ", nrow(.))) +
      xlab("Average inclusion delay") +
      ylab("Annualised reward (%)")
  }
```

The plot looks rather homogeneous...

## Aggregate attestations

eth2 is built to scale to tens of thousands of validators. This introduces overhead from message passing (and inclusion) when these validators are asked to vote on the canonical chain. To alleviate the beacon chain, votes (a.k.a. **individual attestations**) can be **aggregated**.

In particular, an attestation contains five attributes:

- The slot it is attesting for ("**attestation slot**").
- The index of its committee in the slot ("**attestation committee**").
- Its vote for the head of the beacon chain, given by the fork choice rule.
- Its vote for the source, i.e., the last justified checkpoint in its view.
- Its vote for the target, i.e., the checkpoint to be justified in its view.

Since we expect validators to broadly agree in times of low latency, we also expect that a lot of individual attestations will share these same five attributes. We can aggregate such a set of individual attestations $I$ into a single, aggregate, attestation.

<aside>
Aggregators are randomly selected by the beacon chain, whose job it is to collect such individual attestations and package them in aggregates.
</aside>

When we have $N$ active validators, about $N / 32$ are selected to attest for each slot in an epoch. The validators for a slot $s$ are further divided between a few committees. Identical votes from validators in the same committee can be aggregated. Assume that two aggregate attestations were formed from individual attestations of validators in set $C(s, c)$, validators in committee $c$ attesting for slot $s$. One aggregate contains individual attestations from set $I \subseteq C(s, c)$ and the other individual attestations from set $J \subseteq C(s, c)$. We have two cases:

- When the intersection of $I$ and $J$ is non-empty, we cannot aggregate the two aggregates further.
- When the intersection of $I$ and $J$ is empty, the two aggregates can themselves be aggregated, into one containing attestations from validator set $I \cup J$.

In the following, we look at redundant, clashing and individual attestations.

### How many individual attestations are contained in aggregates?

```{r message=FALSE}
all_ats %>%
  .[, .(count=.N), by=contained_ats] %>%
  ggplot() +
  geom_col(aes(x = contained_ats, y = count), fill=myred) +
  ggtitle("Number of individual attestations per aggregate (histogram)",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Number of attestations in aggregate") +
  ylab("Count")
```

A fairly high number of aggregate attestations included in a block are actually individual attestations (the very tall bar on the left side of the plot, where number of individual attestations per aggregate is equal to 1). Nonetheless, a significant number of aggregates tally up between 50 and 100 individual attestations.

We can plot the same, weighing by the size of the validator set in the aggregate, to count how many individual attestations each size of aggregates included.

```{r}
all_ats %>%
  .[, .(count=.N * contained_ats), by=contained_ats] %>%
  ggplot() +
  geom_col(aes(x = contained_ats, y = count), fill=myred) +
  ggtitle("Number of individual attestations per aggregate (histogram, weighted)",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Number of attestations in aggregate") +
  ylab("Number of individual attestations")
```

Overall, we can plot the [Lorenz curve](https://en.wikipedia.org/wiki/Lorenz_curve) of aggregate attestations. This allows us to find out the share of attestations held by the 20% largest aggregates.

```{r}
L <- Lc(all_ats$contained_ats)
```

```{r}
L_tibble <- tibble(p = L$p, L = L$L) %>%
  filter(row_number() %% 100000 == 1 | row_number() == max(row_number()))

L_80q <- quantile(L$L, 0.8, names=FALSE) %>%
  round(digits = 2)

L_tibble %>%
  ggplot() +
  geom_line(aes(x = p, y = L), colour = myred, size = 1.1) +
  geom_abline(slope = 1, intercept = 0, linetype="dotted") +
  geom_vline(xintercept = 0.8, colour = "steelblue", linetype = "dotted", size = 1.1) +
  geom_hline(yintercept = L_80q, colour = "steelblue", size = 1.1) +
  scale_x_continuous(
    breaks = sort(c(c(0.8), with(L_tibble, pretty(range(p))))),
  ) +
  scale_y_continuous(
    breaks = sort(c(c(L_80q), with(L_tibble, pretty(range(p))))),
  ) +
  ggtitle("Lorenz curve of aggregate attestation sizes",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Aggregation percentile") +
  ylab("Cumulative share of attestations")
```

The answer is `r (100 - L_80q * 100)`%.

#### How much savings did aggregates provide?

We compare how many individual attestations exist to how many aggregates were included in blocks.

```{r}
n_aggregates <- all_ats %>% nrow()
savings_ratio <- round(n_individual_ats / n_aggregates, digits=2)

tibble(Name = c("Individual attestations", "Included aggregates", "Savings ratio"),
       Value = c(n_individual_ats, n_aggregates,
                 savings_ratio)) %>%
  paged_table()
```

We have `r round(n_individual_ats / n_aggregates, digits = 2)` times more individual attestations than aggregates, meaning that if we were not aggregating, we would have `r round(n_individual_ats / n_aggregates, digits = 2)` as much data on-chain.

### In how many aggregate attestations is a single attestation included?

We look at all _individual_ attestations in our dataset, i.e., individual, unaggregated votes, and measure how many times they were included in an aggregate.

```{r}
readRDS(here::here("rds_data/appearances_in_aggs.rds")) %>%
  ggplot() +
  geom_col(aes(x = appearances, y = count), fill=myred) +
  scale_y_log10() +
  ggtitle("Number of times an individual attestation is included in an aggregate (histogram)",
          subtitle = str_c("Individual attestations = ", n_individual_ats)) +
  xlab("Number of inclusions") +
  ylab("Count (log10)")
```

Most attestations were included in an aggregate once only

### How many redundant aggregate attestations are there?

We call **redundant** identical aggregate attestations (same five attributes and same set of validator indices) which are included in more than one block. It can happen when a block producer does not see that an aggregate was previously included (e.g., because of latency), or simply when the block producer doesn't pay attention and greedily adds as many aggregates as they know about.

```{r}
readRDS(here::here("rds_data/redundant_ats.rds")) %>%
  ggplot() +
  geom_col(aes(x = appearances, y = count), fill=myred) +
  ggtitle("Number of times one aggregate attestation is included (histogram)",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Number of times redundant") +
  ylab("Count (log10)") +
  scale_y_log10()
```

The mode is 1, which is also the optimal case. A redundant aggregate does not have much purpose apart from bloating the chain.

### How many times did a block include the exact same aggregate attestation more than once?

We could call these **strongly redundant**, as this is pure waste.

```{r}
strong_redundant <- readRDS(here::here("rds_data/appearances_in_same_block.rds"))
n_strong_redundant_twice <- strong_redundant %>%
  pull(count) %>%
  pluck(2)
n_strong_redundant_over_twice <- strong_redundant %>%
  pull(count) %>%
  sum() - n_strong_redundant_twice - strong_redundant %>% pull(count) %>% pluck(1)
strong_redundant %>%
  paged_table()
```

We see that `r n_strong_redundant_twice` times, identical aggregates were included twice in a block.

### How many times were clashing attestations included in blocks?

We define **clashing** attestations as two aggregate attestations included in the same block, with identical attributes (same attesting slot, attesting committee, beacon chain head, source block and target block). We can further define the following two notions, assuming the two aggregate attestations include attestations of validator sets $I$ and $J$ respectively:

- **Weakly clashing:** the two aggregates have different validator indices, $I \neq J$.
- **Strongly clashing:** $I \neq J$ **and** $I \cap J \neq \emptyset$. The two aggregate attestations were incompatible, so could not be aggregated further.

We obtain how many times an attestation weakly clashes with itself, i.e., is included multiple times in a single block with different validator sets. For instance, if an aggregate attestation is included in the same block three times with a different set of validator indices each time, we record that this aggregate is weakly clashing three times with itself. We give below the histogram of this measure.

```{r}
readRDS(here::here("rds_data/weakly_clashing.rds")) %>%
  mutate(clashing = if_else(appearances == 1, "Non-weakly clashing", "Weakly clashing")) %>%
  ggplot() +
  geom_col(aes(x = appearances, y = count, group=clashing, fill=clashing)) +
  scale_y_log10() +
  scale_fill_manual("Clashing type", values = c(myyellow, myred)) +
  ggtitle("Number of times an aggregate attestation is weakly clashing (histogram)",
          subtitle = str_c("Aggregate attestations = ", nrow(all_ats))) +
  xlab("Times clashing") +
  ylab("Count (log10)") +
  xlim(0, 50)
```

From the plot above, we observe that some aggregates were included over 40 times in the same block, all with different sets of validator indices. Still, most aggregates were included once or a few times.

Finding weakly clashing attestations that are not strongly clashing (i.e., which could have been aggregated further) is left for future work as it is more computationally intensive. In particular, for a set of aggregates identical up to their validator indices, one must find which have an empty overlap.

Note that optimally aggregating a set of aggregates is NP-complete! Here is a reduction of the optimal aggregation problem to the [graph colouring](https://en.wikipedia.org/wiki/Graph_coloring). Set aggregate attestations as vertices in a graph, with an edge drawn between two vertices if the validator sets of the two aggregates have a non-empty overlap. In the graph colouring, we look for the minimum number of colours necessary to assign a colour to each vertex such that two connected vertices do not have the same colour. All vertices who share the same colour have an empty overlap, and thus can be combined into an aggregate. The minimum number of colours necessary to colour the graph tells us how few aggregates were necessary to combine a given set of aggregates further.

### How many aggregates in a block are included by another aggregate in the same block?

We now define **subset aggregates**. Suppose two aggregates in the same block with equal attributes (slot, committee index, beacon root, source root and target root) include validator sets $I$ and $J$ respectively. If we have $I \subseteq J$, i.e., if all validators of the first aggregate are also included in the second aggregate, then we call the first aggregate a **subset aggregate** of the second.

<aside>
Note that this analysis is only done for blocks up until slot 20,000 for now.
</aside>

Subset aggregates, much like redundant aggregate attestations (equal aggregates included in more than one block of the canonical chain), can be removed from the finalised chain without losing any voting information. In fact, subset aggregates use much less local information than redundant aggregates. To root out subset aggregates, a client simply must ensure that no aggregate it is prepared to include in a block is a subset aggregate of another. Meanwhile, to root out redundant aggregates, a client must check all past blocks (until the inclusion limit of 32 slots) to ensure that it is not including a redundant aggregate. In a sense, subset aggregate are "worse" as they should be easier to root out.

So among all included aggregates in blocks, how many are subset aggregates?

```{r}
subset_ats <- fread(here::here("rds_data/subset_ats.csv"))
n_aggregates_until <- all_ats %>%
  filter(slot < 20000) %>%
  nrow()

n_subset_ats <- sum(subset_ats$how_many)
percent_subset <- round(n_subset_ats / n_aggregates_until, digits=4) * 100
tibble(Name = c("Subset aggregates", "Included aggregates", "Percentage of subset aggregates"),
       Value = c(n_subset_ats, n_aggregates_until,
                 percent_subset)) %>%
  paged_table()
```

We find that `r percent_subset`% included aggregates are subset aggregates.

#### How often are subset aggregates of size 1?

Taking a look at instances of subset aggregates, we often observe that the subset aggregate has size 1. In other words, it is often the case that a "big" aggregate is included, aggregating very many validators, and then a second aggregate of size 1, namely, an individual attestation, is included too, while this second individual attestation is already aggregated by the first, larger aggregate.

```{r}
n_subset_ind_ats <- sum(subset_ats$how_many_ind)
percent_subset_ind <- round(n_subset_ind_ats / n_subset_ats, digits=4) * 100
tibble(Name = c("Subset aggregates of size 1", "Subset aggregates",
                "Percentage of subset aggregates of size 1"),
       Value = c(n_subset_ind_ats, n_subset_ats,
                 percent_subset_ind)) %>%
  paged_table()
```

A large majority of subset aggregates (`r percent_subset_ind`%) have size 1.

### Aggregates glossary

```{r}
n_size_1_ags <- all_ats %>%
  .[, .(count=.N), by=contained_ats] %>%
  pull(count) %>%
  pluck(1)
n_redundant_ags <- readRDS(here::here("rds_data/redundant_ats.rds")) %>%
  filter(appearances > 1) %>%
  pull(count) %>%
  sum()
```

We've looked at aggregate attestations in a few different ways. We offer here a table to summarise the definitions we have introduced and associated statistics.

| Name | Explanation | Statistics |
|-|-|-|
| Aggregate | Attestation summarising the vote of validators in a single committee | There are `r n_aggregates` aggregates included from slot 0 to slot `r until_slot` |
| Individual attestation | A single validator vote | There are `r n_individual_ats` individual attestations |
| Savings ratio | The ratio of individual attestations to aggregate attestations | The savings ratio is `r savings_ratio` |
| Aggregate of size 1 | An individual attestations included without being aggregated | There are `r n_size_1_ags` aggregates of size 1 |
| Redundant aggregate | An aggregate included more than once on-chain | There are `r n_redundant_ags` redundant aggregates |
| Strongly redundant aggregate | An aggregate included more than once _in the same block_ | There are `r n_strong_redundant_twice + n_strong_redundant_over_twice` strongly redundant aggregates |
| Clashing aggregates | Two aggregates included in the same block differing only by their attesting indices | x |
| Weakly clashing aggregates | Clashing aggregates with attesting indices $I$ and $J$ such that $I \neq J$ | x |
| Strongly clashing aggregates | Clashing aggregates with attesting indices $I$ and $J$ such that $I \neq J$ and $I \cap J \neq \emptyset$. These are aggregates that cannot be aggregated further | x |
| Subset aggregate | An aggregate fully contained in another aggregate included in the same block | There are `r n_subset_ats` subset aggregates until slot 20000, `r percent_subset`% of all aggregates until slot 20000 |
| Subset aggregate of size 1 | A subset aggregate which is an unaggregated individual attestation | There are `r n_subset_ind_ats` subset aggregates of size 1 until slot 20000, `r percent_subset_ind`% of all subset aggregates until slot 20000 |

```{r}
# Disconnect from the database
dbDisconnect(con)
```

